{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Tools 2023, Assignment 3\n",
    "\n",
    "## Sign Language Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment you will implement different deep learning networks to classify images of hands in poses that correspond to letters in American Sign Language. The dataset is contained in the assignment zip file, along with some images and a text file describing the dataset. It is similar in many ways to other MNIST datasets.\n",
    "\n",
    "The main aims of the assignment are:\n",
    "\n",
    " - To implement and train different types of deep learning network;\n",
    " \n",
    " - To systematically optimise the architecture and parameters of the networks;\n",
    "  \n",
    " - To explore over-fitting and know what appropriate actions to take in these cases.\n",
    " \n",
    "\n",
    "It is the intention that this assignment will take you through the process of implementing and optimising deep learning approaches. The way that you work is more important than the results for this assignment, as what is most crucial for you to learn is how to take a dataset, understand the problem, write appropriate code, optimize performance and present results. A good understanding of the different aspects of this process and how to put them together well (which will not always be the same, since different problems come with different constraints or difficulties) is the key to being able to effectively use deep learning techniques in practice.\n",
    "\n",
    "This assignment relates to the following ACS CBOK areas: abstraction, design, hardware and software, data and information, HCI and programming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "A client is interested in having you (or rather the company that you work for) investigate whether it is possible to develop an app that would enable American sign language to be translated for people that do not sign, or those that sign in different languages/styles. They have provided you with a labelled data of images related to signs (hand positions) that represent individual letters in order to do a preliminary test of feasibility.\n",
    "\n",
    "Your manager has asked you to do this feasibility assessment, but subject to a constraint on the computational facilities available.  More specifically, you are asked to do **no more than 50 training runs in total** (including all models and hyperparameter settings that you consider).  \n",
    "\n",
    "In addition, you are told to **create a validation set and any necessary test sets using _only_ the supplied testing dataset.** It is unusual to do this, but here the training set contains a lot of non-independent, augmented images and it is important that the validation images must be totally independent of the training data and not made from augmented instances of training images.\n",
    "\n",
    "The clients have asked to be informed about the following:\n",
    " - **unbiased accuracy** estimate of a deep learning model (since DL models are fast when deployed)\n",
    " - the letter with the lowest individual accuracy\n",
    " - the most common error (of one letter being incorrectly labelled as another)\n",
    " \n",
    "Your manager has asked you to create a jupyter notebook that shows the following:\n",
    " - loading the data, checking it, fixing any problems, and displaying a sample\n",
    " - training and optimising both **densely connected** *and* **CNN** style models\n",
    " - finding the best one, subject to a rapid turn-around and corresponding limit of 50 training runs in total\n",
    " - reporting clearly what networks you have tried, the method you used to optimise them, the associated learning curves, their summary performance and selection process to pick the best model\n",
    "     - this should be clear enough that another employee, with your skillset, should be able to take over from you and understand your methods\n",
    " - results from the model that is selected as the best, showing the information that the clients have requested\n",
    " - a statistical test between the best and second-best models, to see if there is any significant difference in performance (overall accuracy)\n",
    " - it is hoped that the accuracy will exceed 96% overall and better than 90% for every individual letter, and you are asked to:\n",
    "     - report the overall accuracy\n",
    "     - report the accuracy for each individual letter\n",
    "     - write a short recommendation regarding how likely you think it is to achieve these goals either with the current model or by continuing to do a small amount of model development/optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide to Assessment\n",
    "\n",
    "This assignment is much more free-form than others in order to test your ability to run a full analysis like this one from beginning to end, using the correct procedures. So you should use a methodical approach, as a large portion of the marks are associated with the decisions that you take and the approach that you use.  There are no marks associated with the performance - just report what you achieve, as high performance does not get better marks - to get good marks you need to use the right steps, as you've used in other assignments and workshops.\n",
    "\n",
    "Make sure that you follow the instructions found in the scenario above, as this is what will be marked.  And be careful to do things in a way that gives you an *unbiased* result.\n",
    "\n",
    "The notebook that you submit should be similar to those in the other assignments, where it is important to clearly structure your outputs and code so that it could be understood by your manager or your co-worker - or, even more importantly, the person marking it! This does not require much writing, beyond the code, comments and the small amount that you've seen in previous assignments.  Do not write long paragraphs to explain every detail of everything you do - it is not that kind of report and longer is definitely not better.  Just make your code clear, your outputs easy to understand (short summaries often help here), and include a few small markdown cells that describe or summarise things when necessary.\n",
    "\n",
    "Marks for the assignment will be determined according to the general rubric that you can find on MyUni, with a breakdown into sections as follows:\n",
    " - 10%: Loading, investigating, manipulating and displaying data\n",
    " - 20%: Initial model successfully trained (and acting as a baseline)\n",
    " - 45%: Optimisation of an appropriate set of models in an appropriate way (given the constraint of 50 training runs)\n",
    " - 25%: Comparison of models, selection of the best two and reporting of final results\n",
    "\n",
    "Remember that most marks will be for the **steps you take**, rather than the achievement of any particular results. There will also be marks for showing appropriate understanding of the results that you present.  \n",
    "\n",
    "What you need to do this assignment can all be found in the first 10 weeks of workshops, lectures and also the previous two assignments. The one exception to this is the statistical test, which will be covered in week 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Instructions\n",
    "\n",
    "While you are free to use whatever IDE you like to develop your code, your submission should be formatted as a Jupyter notebook that interleaves Python code with output, commentary and analysis. \n",
    "- Your code must use the current stable versions of python libraries, not outdated versions.\n",
    "- All data processing must be done within the notebook after calling appropriate load functions.\n",
    "- Comment your code, so that its purpose is clear to the reader!\n",
    "- In the submission file name, do not use spaces or special characters.\n",
    "\n",
    "The marks for this assignment are mainly associated with making the right choices and executing the workflow correctly and efficiently. Make sure you have clean, readable code as well as producing outputs, since your coding will also count towards the marks (however, excessive commenting is discouraged and will lose marks, so aim for a modest, well-chosen amount of comments and text in outputs).\n",
    "\n",
    "This assignment can be solved using methods from sklearn, pandas, matplotlib and keras, as presented in the workshops. Other high-level libraries should not be used, even though they might have nice functionality such as automated hyperparameter or architecture search/tuning/optimisation. For the deep learning parts please restrict yourself to the library calls used in workshops 7-10 or ones that are very similar to these. You are expected to search and carefully read the documentation for functions that you use, to ensure you are using them correctly.\n",
    "\n",
    "As ususal, feel free to use code from the workshops as a base for this assignment but be aware that they will normally not do *exactly* what you want (code examples rarely do!) and so you will need to make suitable modifications.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Prepareation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sign_mnist_train.csv')\n",
    "test = pd.read_csv('sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.isnull().any().sum())\n",
    "print(test.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_unique = train['label'].unique()\n",
    "test_labels_unique = test['label'].unique()\n",
    "\n",
    "print(f\"labels in train dataset: {sorted(train_labels_unique)}\")\n",
    "print(f\"labels in test dataset: {sorted(test_labels_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['label'] != 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_unique = train['label'].unique()\n",
    "test_labels_unique = test['label'].unique()\n",
    "\n",
    "print(f\"labels in train dataset: {sorted(train_labels_unique)}\")\n",
    "print(f\"labels in test dataset: {sorted(test_labels_unique)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels_min = train.drop('label', axis=1).values.min()\n",
    "train_pixels_max = train.drop('label', axis=1).values.max()\n",
    "\n",
    "test_pixels_min = test.drop('label', axis=1).values.min()\n",
    "test_pixels_max = test.drop('label', axis=1).values.max()\n",
    "\n",
    "print(f\"Train pixel values range: {train_pixels_min} - {train_pixels_max}\")\n",
    "print(f\"Test pixel values range: {test_pixels_min} - {test_pixels_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train.drop('label', axis=1).values\n",
    "train_labels = train['label'].values\n",
    "\n",
    "unique_labels = np.unique(train_labels)\n",
    "fig, axes = plt.subplots(3, 8, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(24):\n",
    "    label_index = np.where(train_labels == unique_labels[i])[0][0]\n",
    "    axes[i].imshow(train_images[label_index].reshape(28, 28), cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {unique_labels[i]}\")\n",
    "    axes[i].axis('off')  # Hide axis\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['label'].values\n",
    "true_labels = train_labels\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = np.bincount(true_labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(range(len(label_counts)), label_counts)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Distribution of Labels in Training Set')\n",
    "plt.xticks(range(len(label_counts)), [chr(i + 65) for i in range(len(label_counts))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = test['label'].values\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = np.bincount(true_labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(range(len(label_counts)), label_counts)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Distribution of Labels in Test Set')\n",
    "plt.xticks(range(len(label_counts)), [chr(i + 65) for i in range(len(label_counts))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test.drop('label', axis=1).values / 255.0\n",
    "\n",
    "# Reshape images to have a single channel (grayscale)\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Baseline Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),  # Flattens the input\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(25, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(16, kernel_size=(3, 3), activation='selu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='selu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='selu'),\n",
    "    Dense(25, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='accuracy', patience=4, restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_letter(model):\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Calculate accuracy for each letter\n",
    "    for i in range(25): # since there are 24 classes\n",
    "        correct_predictions = np.sum((predicted_labels == i) & (true_labels == i))\n",
    "        total_true = np.sum(true_labels == i)\n",
    "        acc = correct_predictions / total_true if total_true != 0 else 0\n",
    "        \n",
    "        if i == 9:\n",
    "            accuracies.append(1.0)\n",
    "        else:\n",
    "            accuracies.append(acc)\n",
    "\n",
    "    # Finding the letter with the lowest accuracy\n",
    "    lowest_acc = np.argmin(accuracies)\n",
    "\n",
    "    print(f\"Letter with the lowest accuracy: {chr(65 + lowest_acc)} with accuracy {accuracies[lowest_acc]*100:.2f}%\")\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_mismatch(model):\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    # Finding mismatches between true and predicted labels\n",
    "    mismatches = [(true, predicted) for true, predicted in zip(true_labels, predicted_labels) if true != predicted]\n",
    "\n",
    "    # Counting mismatches to find the most common error\n",
    "    error_counts = Counter(mismatches)\n",
    "\n",
    "    most_common, error_count = error_counts.most_common(1)[0]\n",
    "\n",
    "    print(f\"The most common error is {chr(65 + most_common[0])} being mislabeled as {chr(65 + most_common[1])} with {error_count} occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn_factory(hiddensizes, actfn, optimizer, learningrate=0.0001, kernel_size = 3, dropout = 0.1):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv2D(filters=hiddensizes[0], kernel_size=3, \n",
    "                                  strides=1, activation=actfn, padding=\"same\", \n",
    "                                  input_shape=[28, 28, 1]))    \n",
    "    model.add(Dropout(0.1))              \n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    for n in hiddensizes[1:-1]:\n",
    "        model.add(Conv2D(filters=n, kernel_size=3, strides=1, \n",
    "                                      padding=\"same\", activation=actfn))  \n",
    "                                      \n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "    model.add(Conv2D(filters=hiddensizes[-1], kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", activation=actfn))  \n",
    "                                  # 2nd Conv\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(25, activation = \"softmax\"))  \n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "                  optimizer=optimizer(learning_rate=learningrate), metrics=[\"accuracy\"])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: \n",
    "\n",
    "- Activation function: Selu\n",
    "- Optimizer: Nadam (Learning rate: 0.0005)\n",
    "- Kernel size: 3x3\n",
    "- Dropout rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"selu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0005,\n",
    "                        kernel_size = 3, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = model_1.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_model1 = find_worst_letter(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: \n",
    "\n",
    "- Activation function: ReLU\n",
    "- Optimizer: Nadam (Learning rate: 0.0005)\n",
    "- Kernel size: 3x3\n",
    "- Dropout rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0005,\n",
    "                        kernel_size = 3, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = model_2.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_model2 = find_worst_letter(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: \n",
    "- Activation function: ReLU\n",
    "- Optimizer: Nadam (Learning rate: 0.0005)\n",
    "- Kernel size: 5x5\n",
    "- Dropout rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0005,\n",
    "                        kernel_size = 5, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = model_3.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = model_3.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_model3 = find_worst_letter(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4:\n",
    "- Activation function: ReLU\n",
    "- Optimizer: SGD (Learning rate: 0.01)\n",
    "- Kernel size: 3x3\n",
    "- Dropout rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.SGD, learningrate = 0.01,\n",
    "                        kernel_size = 3, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = model_4.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_4.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_model4 = find_worst_letter(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5:\n",
    "- Activation function: ReLU\n",
    "- Optimizer: Nadam (Learning rate: 0.0001)\n",
    "- Kernel size: 5x5\n",
    "- Dropout rate: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0001,\n",
    "                        kernel_size = 5, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_5.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = model_5.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_model5 = find_worst_letter(model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "**Model Architecture**: We utilized a CNN (Convolutional Neural Network) with multiple convolutional layers, dropouts, and dense layers for classification.\n",
    "\n",
    "**Optimization Methods**: We experimented with various configurations like activation functions, optimizers, learning rates, kernel sizes, and dropout rates.\n",
    "\n",
    "**Early Stopping**: We introduced an early stopping mechanism to halt training if there's no improvement in accuracy after 4 epochs to avoid overfitting and save computation time.\n",
    "\n",
    "**Evaluation Metrics**: We used categorical cross-entropy as the loss function and accuracy as the metric. We also evaluated each model on its ability to identify the letter with the lowest individual accuracy and its most common labeling error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "history_list = [history_1, history_2, history_3, history_4, history_5]\n",
    "model_name = ['model 1' , 'model 2', 'model 3', 'model 4', 'model 5']\n",
    "for i in range (5):\n",
    "    if (i == 0):\n",
    "        ax1 = plt.subplot(2, 3, i + 1)\n",
    "    else:\n",
    "        ax = plt.subplot(2, 3, i + 1, sharey = ax1)\n",
    "    train_acc = history_list[i].history['accuracy']\n",
    "    val_acc = history_list[i].history['val_accuracy']\n",
    "\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title(model_name[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "letter_acc_list = [letter_acc_model1, letter_acc_model2, letter_acc_model3, letter_acc_model4, letter_acc_model5]\n",
    "model_name = ['model 1' , 'model 2', 'model 3', 'model 4', 'model 5']\n",
    "for i in range (5):\n",
    "    if (i == 0):\n",
    "        ax1 = plt.subplot(3, 2, i + 1)\n",
    "    else:\n",
    "        ax = plt.subplot(3, 2, i + 1, sharey = ax1)\n",
    "    \n",
    "    plt.bar(range(len(letter_acc_list[i])), letter_acc_list[i])\n",
    "    plt.title(model_name[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 5 models, Model 3 shows the highest test accuracy of 98.80%, Letter with the lowest accuracy is 90.38. It uses the ReLU activation function, Nadam optimizer with a learning rate of 0.0005, and a kernel size of 5x5. The second best model is Model 5, it has test accuracy of 97.25, Letter with the lowest accuracy is 88.25.It uses the ReLU activation function, Nadam optimizer with a learning rate of 0.0001, and a kernel size of 5x5. Thus, Model 3 and Model 5 is our recommended model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_1 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0005,\n",
    "                        kernel_size = 5, dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = final_model_1.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = final_model_1.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_final_model_1 = find_worst_letter(final_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(final_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_2 = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0001,\n",
    "                        kernel_size = 5, dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = final_model_2.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = final_model_2.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_final_model_2 = find_worst_letter(final_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(final_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(letter_acc_final_model_1)), letter_acc_final_model_1)\n",
    "plt.title(\"final model 1 accuracy for each letter\")\n",
    "ax = plt.subplot(1, 2, 2, sharey = ax)\n",
    "plt.bar(range(len(letter_acc_final_model_2)), letter_acc_final_model_2)\n",
    "plt.title(\"final model 2 accuracy for each letter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the final two model:\n",
    "\n",
    "**Overall Accuracy:**\n",
    "\n",
    "final model 1: 98.70%\n",
    "\n",
    "final model 2: 97.64%\n",
    "\n",
    "**Accuracy for Each Individual Letter:**\n",
    "\n",
    "For final model 1:\n",
    "\n",
    "S: 90.38% (Lowest accuracy)\n",
    "\n",
    "Other letters: Above 90%\n",
    "\n",
    "For final model 2:\n",
    "\n",
    "Y: 88.25% (Lowest accuracy)\n",
    "\n",
    "Other letters: Above 90%\n",
    "\n",
    "**Recommendation:**\n",
    "\n",
    "Both models exceed the overall accuracy goal of 96%. However, when examining individual letters, final model 2 (for letter 'Y') fall slightly below the desired 90% threshold. So final model 1 is better.\n",
    "\n",
    "However, when examining individual letters, final model 1, the accuracy is slightly upon the 90% threshold, so we may try possible steps include using data augmentation techniques for underrepresented letters, fine-tuning the model architecture, or employing ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = model_cnn_factory(hiddensizes = [32, 64, 64, 64, 32], actfn = \"relu\", \n",
    "                        optimizer = keras.optimizers.Nadam, learningrate = 0.0005,\n",
    "                        kernel_size = 5, dropout = 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = final_model.fit(train_images, train_labels, batch_size=64, verbose = 0,\n",
    "                        epochs=epochs, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "loss, accuracy = final_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_acc_final_model = find_worst_letter(final_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(letter_acc_final_model)), letter_acc_final_model)\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_mismatch(final_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result is:\n",
    "\n",
    "Overall Accuracy: 98.21%\n",
    "\n",
    "Letter with the lowest accuracy: R with accuracy 91.42%\n",
    "\n",
    "The most common error is N being mislabeled as M with 25 occurrences.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
